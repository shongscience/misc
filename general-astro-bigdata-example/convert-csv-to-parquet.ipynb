{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract subsamples from HR4 Big Data catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate edges \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "import gc\n",
    "\n",
    "# plot settings\n",
    "plt.rc('font', family='serif') \n",
    "plt.rc('font', serif='Times New Roman') \n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext   \n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "#sc = SparkContext(master='local[3]', appName='calgraph')\n",
    "sqlsc = SQLContext(sc)\n",
    "#sc.setCheckpointDir(\"./checkpoints\")\n",
    "#sc.setCheckpointDir(\"hdfs://localhost:8020/myhdfs/spark/checkpoints\")\n",
    "sc.setCheckpointDir(\"hdfs://master:54310/tmp/spark/checkpoints\")\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark import Row\n",
    "from pyspark.sql.window import Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "halo_schema = T.StructType([ \\\n",
    "                            T.StructField('haloid', T.IntegerType(), False), \\\n",
    "                            T.StructField('px', T.FloatType(), False), \\\n",
    "                            T.StructField('py', T.FloatType(), False), \\\n",
    "                            T.StructField('pz', T.FloatType(), False), \\\n",
    "                            T.StructField('vx', T.FloatType(), False), \\\n",
    "                            T.StructField('vy', T.FloatType(), False), \\\n",
    "                            T.StructField('vz', T.FloatType(), False), \\\n",
    "                            T.StructField('halomass', T.FloatType(), False), \\\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "halodf = sqlsc.read.csv(\"hdfs://master:54310/data/cosmo/hr4/halo_z0.csv\",\\\n",
    "                        header=False, schema = halo_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+----------+----------+---------+-------------+\n",
      "|   haloid|       px|       py|       pz|        vx|        vy|       vz|     halomass|\n",
      "+---------+---------+---------+---------+----------+----------+---------+-------------+\n",
      "|322225520|106.23875|2820.2603|310.53067|   -593.39|  42.42728|117.49196|3.29162502E14|\n",
      "|127093960|1015.0091| 3070.103|2687.5447|-361.36716| -34.88201|   980.29|  5.796312E14|\n",
      "| 95586173|1150.7571| 656.3275|195.96417|  295.5281|-117.53244|203.30292| 7.4870011E14|\n",
      "+---------+---------+---------+---------+----------+----------+---------+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "halodf.show(3,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- haloid: integer (nullable = true)\n",
      " |-- px: float (nullable = true)\n",
      " |-- py: float (nullable = true)\n",
      " |-- pz: float (nullable = true)\n",
      " |-- vx: float (nullable = true)\n",
      " |-- vy: float (nullable = true)\n",
      " |-- vz: float (nullable = true)\n",
      " |-- halomass: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "halodf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as a parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.39 ms, sys: 10.2 ms, total: 16.6 ms\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "halodf \\\n",
    "    .write.option(\"compression\", \"snappy\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"hdfs://master:54310/data/cosmo/hr4/hr4-fof-halo-z0.parquet.snappy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
